{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2925352-cf72-4358-8b66-cc138aa866e9",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"> </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Concrete Crack Image Classification — Model training\n",
    "\n",
    "**Short description:**  \n",
    "This notebook performs transfer learning using a ResNet50 backbone (pretrained on ImageNet) to classify concrete crack images. It extracts a zip dataset, creates Keras `ImageDataGenerator` flows for training/validation, builds a model with ResNet50 base + a classification head, trains the model, and saves the trained model.\n",
    "\n",
    "**Dataset:**\n",
    "\n",
    "Download the dataset from: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/concrete_data_week3.zip\n",
    "\n",
    "**Objectives**\n",
    "- Extract the zipped dataset and create a working directory  with `zipfile`. \n",
    "- Create `ImageDataGenerator` flows for training and validation with `preprocess_input` suited for ResNet.  \n",
    "- Build a Keras `Sequential` model using a frozen ResNet50 base (pooling='avg') and a dense softmax head for `num_classes`.  \n",
    "- Train the model and save it to disk (`classifier_resnet_model.h5`).  \n",
    "\n",
    "**Notice about documentation:**  \n",
    "The original notebook submission (course assignment) was kept intact. I have **only modified documentation (comments, headings, markdown)** and made **minimal, necessary corrections** to ensure the notebook runs without errors. All rights related to the lab/workshop design and original exercise belong exclusively to **IBM Corporation**. This notebook includes additional documentation for clarity, but the intellectual property of the original exercise is retained by IBM.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. Dependencies & execution instructions  \n",
    "2. Unzip dataset and inspect directories \n",
    "3. Define global constants\n",
    "4. ImageDataGenerator & directory flows \n",
    "5. Model construction (ResNet50 base + head)  \n",
    "6. Training and saving the model  \n",
    "7. Notes & reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dependencies & execution instructions\n",
    "\n",
    "This section installs and imports required Python packages.  \n",
    "\n",
    "**Recommended local execution steps:**\n",
    "\n",
    "1. Create and activate a Python virtual environment:\n",
    "   - `python -m venv venv`\n",
    "   - `source venv/bin/activate` (macOS / Linux) or `venv\\Scripts\\activate` (Windows)\n",
    "2. Install dependencies:\n",
    "   - `pip install -r requirements.txt`\n",
    "3. Launch Jupyter Notebook:\n",
    "   - `jupyter notebook`\n",
    "4. Open this notebook and run cells top-to-bottom.\n",
    "\n",
    "**Note:** Make sure to have the `concrete_data_week3.zip` in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea0e051-001b-488c-b2c5-87a682b745b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import zipfile\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Unzip dataset and inspect directories\n",
    "\n",
    "Extracts `concrete_data_week3.zip` into `concrete_data_week3/`. After extraction, confirm the structure contains `train/` and `valid/` subdirectories with class subfolders inside (one folder per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd64f37-fae9-4f7f-b25a-3075b025a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = Path(\"concrete_data_week3.zip\")\n",
    "\n",
    "extract_dir = Path(\"concrete_data_week3\")\n",
    "extract_dir.mkdir(exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab34b495-4e94-4d32-b8da-e624146cb339",
   "metadata": {},
   "source": [
    "**Important Note:** \n",
    "\n",
    "There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50** error. So please **DO NOT DO IT**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f1629b-6a7b-417b-8211-4cad9f541da0",
   "metadata": {},
   "source": [
    "## 3) Define global constants\n",
    "\n",
    "Define constants:\n",
    "\n",
    "1. There are two clases: `Positive` and `Negative`. `num_classes` is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, the images have to be resized from (227 x 227) to (224 x 224).\n",
    "3. Perform training and validation with batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b869e6-88ef-4d50-a337-c072fa384587",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) ImageDataGenerator & directory flows\n",
    "\n",
    "We create `ImageDataGenerator` with `preprocess_input` (ResNet50). Then we create `train_generator` and `validation_generator` via `flow_from_directory()` using the target size (224×224) and categorical class mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a656dd-0656-4a1c-80d9-65859faa7649",
   "metadata": {},
   "source": [
    "Set the **preprocessing_function** argument to *preprocess_input* in order to preprocess the images the same way the images used to train ResNet50 model were processed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a55ab-4e21-42bd-9a5d-60124e306fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8625422-6d7b-4e3f-b996-211e88e773c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f817647-eaad-4d68-9af9-222e0dd1b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Model construction (ResNet50 base + head)\n",
    "\n",
    "We create a `Sequential` model and add a ResNet50 base (`include_top=False`, `pooling='avg'`, `weights='imagenet'`) followed by a Dense softmax classification head for `num_classes`. The ResNet base is frozen (`trainable = False`) before compiling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd441e7-2c95-4c70-8e21-3643636fc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339754c-09cb-471a-890b-b17ce2e9e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a03d8-84e8-49fa-aa58-8d0e20a0ffc5",
   "metadata": {},
   "source": [
    "Define output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206145b8-45f9-43c6-9db6-1ad4bd073d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04386088-61ae-48d8-8a71-295e99cd9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdfa175-97d4-416b-a78f-930f3f971362",
   "metadata": {},
   "source": [
    "The model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is the Dense layer defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6058d-d5bc-4150-a5c2-8b3000f39865",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6a949d-86d5-4b23-a165-f5545012da44",
   "metadata": {},
   "source": [
    "Since the ResNet50 model has already been trained, the ResNet part won't be retrained, only the dense output layer will be trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dddb1-6c60-4909-8781-43bbe3f49614",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdba85e-ea71-4b92-8aec-9073aa24f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Training and saving the model \n",
    "\n",
    "Compile the model with `adam` optimizer and `categorical_crossentropy` loss, train for `num_epochs` with steps determined by the generators, and then save the trained model as `classifier_resnet_model.h5`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab0ab4-bf53-418b-b257-2dd759ed5af7",
   "metadata": {},
   "source": [
    "Compile the model using the **adam** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a432df-923b-4342-9b80-40f56b26c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c3174-911e-48e6-9328-afd9f22d7e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02c9e7-7606-407a-b257-981c89ee1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498940f-4bfe-46e7-b37f-c349c29c4c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Notes & reproducibility\n",
    "\n",
    "- `keras` can be the standalone package or `tensorflow.keras`. If you use TensorFlow 2.x, prefer `from tensorflow.keras...` and install `tensorflow`.  \n",
    "- If the machine has a GPU, ensure the correct TensorFlow/PyTorch GPU build is installed to accelerate training.  \n",
    "- If dataset sizes are large, adjust `batch_size_training` and `batch_size_validation` to fit memory / GPU capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d197a4f2-fbc4-44a1-a2fa-d7d548cd2d01",
   "metadata": {},
   "source": [
    "## About the Authors:\n",
    "\n",
    " [Alex Aklson](https://www.linkedin.com/in/aklson/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDL0321ENSkillsNetwork951-2022-01-01)\n",
    "\n",
    "\n",
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week2_LAB1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280eedc9-9bde-4d5d-8358-1c144f18baeb",
   "metadata": {},
   "source": [
    "\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
    "| 2023-01-03  | 3.0  | Artem |  Updated the file import section|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975b95f-2884-45db-acf0-5398957793d1",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "prev_pub_hash": "cf2970a1d2c549fe86023eaa076d0ce4936c4275baf2cccfdad8fe6ce3a8a6c2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
